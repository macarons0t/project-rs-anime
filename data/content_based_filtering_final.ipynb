{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5af2ec",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "```{r}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91a5ff",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1bb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "anime_df = pd.read_csv('data/anime.csv', delimiter=',')\n",
    "rating_df = pd.read_csv('data/rating.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51338e73",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load and Preprocess Data ---\n",
    "# Load datasets\n",
    "anime_df = pd.read_csv('data/anime.csv', delimiter=',')\n",
    "rating_df = pd.read_csv('data/rating.csv', delimiter=',')\n",
    "\n",
    "# Clean rating data by removing -1 and averaging duplicate ratings\n",
    "rating_clean = rating_df[rating_df['rating'] != -1]\n",
    "rating_clean = rating_clean.groupby(['user_id', 'anime_id']).agg({'rating': 'mean'}).reset_index()\n",
    "\n",
    "# Merge anime and rating data\n",
    "merged_df = pd.merge(rating_clean, anime_df, on='anime_id', how='inner')\n",
    "\n",
    "# Prepare the data for embedding: Combine name, genre, type, and episodes\n",
    "# Handle potential NaN values by filling them with empty strings\n",
    "anime_df['name'] = anime_df['name'].fillna('')\n",
    "anime_df['genre'] = anime_df['genre'].fillna('')\n",
    "anime_df['type'] = anime_df['type'].fillna('')\n",
    "anime_df['episodes'] = anime_df['episodes'].fillna('')\n",
    "\n",
    "# Remove commas from the 'genre' column\n",
    "anime_df['genre'] = anime_df['genre'].str.replace(',', ' ')\n",
    "\n",
    "\n",
    "# Create a combined text string for each anime\n",
    "anime_combined_features = []\n",
    "for index, row in anime_df.iterrows():\n",
    "    combined_text = f\"{row['name']} genre: {row['genre']} type: {row['type']} episodes: {row['episodes']}\"\n",
    "    anime_combined_features.append(combined_text)\n",
    "\n",
    "anime_id_to_name = dict(zip(anime_df['anime_id'], anime_df['name'])) # Still useful for displaying recommendations\n",
    "name_to_anime_id = dict(zip(anime_df['name'], anime_df['anime_id'])) # Still useful for reverse lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0429f41",
   "metadata": {},
   "source": [
    "### Load pretrained model and generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load Pretrained Model and Generate Embeddings ---\n",
    "def load_pretrained_model(model_name: str):\n",
    "    \"\"\"Loads a SentenceTransformer model.\"\"\"\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "model = load_pretrained_model('all-MiniLM-L6-v2') # Smaller, faster model for demonstration\n",
    "\n",
    "print(\"Generating anime embeddings (this might take a while for large datasets)...\")\n",
    "# Use the combined features for embedding generation\n",
    "anime_embeddings = model.encode(anime_combined_features, show_progress_bar=True)\n",
    "print(f\"Generated {anime_embeddings.shape[0]} embeddings of dimension {anime_embeddings.shape[1]}\")\n",
    "\n",
    "# Create a mapping from anime_id to its embedding\n",
    "anime_id_to_embedding = {\n",
    "    anime_df.loc[i, 'anime_id']: anime_embeddings[i]\n",
    "    for i in range(len(anime_df))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c40f4f2",
   "metadata": {},
   "source": [
    "### Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b57b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Calculate Cosine Similarity ---\n",
    "# For efficient calculation, we will calculate similarity between all anime embeddings\n",
    "print(\"Calculating cosine similarity matrix...\")\n",
    "anime_similarity_matrix = cosine_similarity(anime_embeddings)\n",
    "print(\"Cosine similarity matrix calculated.\")\n",
    "\n",
    "# Create a mapping from index in similarity matrix back to anime_id\n",
    "index_to_anime_id = {i: anime_df.loc[i, 'anime_id'] for i in range(len(anime_df))}\n",
    "anime_id_to_index = {anime_df.loc[i, 'anime_id']: i for i in range(len(anime_df))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb43f4",
   "metadata": {},
   "source": [
    "### Implement Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365abf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Implement Nearest Neighbors ---\n",
    "def get_nearest_neighbors(anime_id: int, similarity_matrix: np.ndarray, top_n: int = 10):\n",
    "    \"\"\"\n",
    "    Finds the top_n most similar animes for a given anime_id.\n",
    "    Excludes the anime itself.\n",
    "    \"\"\"\n",
    "    if anime_id not in anime_id_to_index:\n",
    "        return []\n",
    "\n",
    "    anime_idx = anime_id_to_index[anime_id]\n",
    "    similarities = similarity_matrix[anime_idx]\n",
    "\n",
    "    # Get indices of top_n+1 most similar items (including itself)\n",
    "    # Use argsort to get indices, then reverse to get descending order of similarity\n",
    "    top_similar_indices = similarities.argsort()[::-1][1:top_n + 1] # [1:] to exclude itself\n",
    "\n",
    "    # Map indices back to anime_ids and their similarity scores\n",
    "    nearest_neighbors = []\n",
    "    for idx in top_similar_indices:\n",
    "        neighbor_anime_id = index_to_anime_id[idx]\n",
    "        neighbor_similarity = similarities[idx]\n",
    "        nearest_neighbors.append((neighbor_anime_id, neighbor_similarity))\n",
    "\n",
    "    return nearest_neighbors\n",
    "\n",
    "# Sample usage:\n",
    "# print(\"\\nNearest neighbors for Anime A (ID 1):\")\n",
    "# print(get_nearest_neighbors(1, anime_similarity_matrix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de5115",
   "metadata": {},
   "source": [
    "### Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b40dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Generate Recommendations ---\n",
    "def recommend_for_user(user_id: int, rating_data: pd.DataFrame, similarity_matrix: np.ndarray, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Generates recommendations for a user based on their watched anime and similar items.\n",
    "    This is a basic user-based collaborative filtering approach using item-item similarity.\n",
    "    \"\"\"\n",
    "    user_watched_anime = rating_data[rating_data['user_id'] == user_id]\n",
    "    if user_watched_anime.empty:\n",
    "        print(f\"User {user_id} has no watched anime data.\")\n",
    "        return []\n",
    "\n",
    "    recommended_anime_scores = {}\n",
    "    already_watched_anime_ids = set(user_watched_anime['anime_id'].tolist())\n",
    "\n",
    "    for _, row in user_watched_anime.iterrows():\n",
    "        watched_anime_id = row['anime_id']\n",
    "        watched_rating = row['rating']\n",
    "\n",
    "        # Get nearest neighbors for the watched anime\n",
    "        neighbors = get_nearest_neighbors(watched_anime_id, similarity_matrix, top_n=50) # Get more neighbors to choose from\n",
    "\n",
    "        for neighbor_anime_id, similarity_score in neighbors:\n",
    "            # Only recommend if not already watched by the user\n",
    "            if neighbor_anime_id not in already_watched_anime_ids:\n",
    "                # Simple aggregation: sum of (similarity * user_rating_for_watched_item)\n",
    "                # You can use more sophisticated weighted averages here\n",
    "                if neighbor_anime_id not in recommended_anime_scores:\n",
    "                    recommended_anime_scores[neighbor_anime_id] = 0\n",
    "                recommended_anime_scores[neighbor_anime_id] += similarity_score * watched_rating\n",
    "\n",
    "    # Sort recommendations by score in descending order\n",
    "    sorted_recommendations = sorted(recommended_anime_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Get the top_k recommendations, retrieving names\n",
    "    final_recommendations = []\n",
    "    for anime_id, score in sorted_recommendations[:top_k]:\n",
    "        anime_name = anime_id_to_name.get(anime_id, f\"Unknown Anime (ID: {anime_id})\")\n",
    "        final_recommendations.append({'anime_id': anime_id, 'name': anime_name, 'score': score})\n",
    "\n",
    "    return final_recommendations\n",
    "\n",
    "# Example usage:\n",
    "# user_id_to_test = 1\n",
    "# recommendations = recommend_for_user(user_id_to_test, rating_clean, anime_similarity_matrix, top_k=10)\n",
    "# print(f\"\\nRecommendations for User {user_id_to_test}:\")\n",
    "# for rec in recommendations:\n",
    "#     print(f\"  - {rec['name']} (ID: {rec['anime_id']}) Score: {rec['score']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c56d6a",
   "metadata": {},
   "source": [
    "### Evaluation (using MAP@10 and NDCG@10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0fd76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T07:56:17.196109Z",
     "iopub.status.busy": "2025-06-26T07:56:17.195463Z",
     "iopub.status.idle": "2025-06-26T08:41:52.035363Z",
     "shell.execute_reply": "2025-06-26T08:41:52.034451Z",
     "shell.execute_reply.started": "2025-06-26T07:56:17.196088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb14b6f6904d4981a2b298fe23af6591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ba92f3ff974c698ca6d5e942c15d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17773ed48eae45e0b762dcba602f281c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740b824a18184bc982d7c0b2e522cd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33791145dc4845699ac1d6242107f9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4277a1b771de49d9a178946392cd6e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46d7919d11a411eb2f9d124073c31ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1a22d3bfce42b29be15cec3b4fbcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b744a82c20f040ffbbce36d6b4c61ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc8d13401764443ac67a81d8db637a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6189d2ad32c44ae870eda824b994baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anime embeddings (this might take a while for large datasets)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60806bb812ac40a68f12b28e972c564d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 12294 embeddings of dimension 384\n",
      "Calculating cosine similarity matrix...\n",
      "Cosine similarity matrix calculated.\n",
      "\n",
      "Starting evaluation for MAP@10 and NDCG@10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating users: 100%|██████████| 61658/61658 [45:10<00:00, 22.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Average MAP@10: 0.0301\n",
      "Average NDCG@10: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Evaluation (MAP@10 and NDCG@10) ---\n",
    "\n",
    "# To evaluate, we need to split data into train and test sets.\n",
    "# We'll use the train set to generate recommendations and the test set as ground truth.\n",
    "train_rating, test_rating = train_test_split(rating_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure all anime_ids in test_rating are present in anime_id_to_index for embedding lookups\n",
    "# Filter out test ratings where anime_id is not in our processed anime_df\n",
    "test_rating = test_rating[test_rating['anime_id'].isin(anime_df['anime_id'])]\n",
    "\n",
    "def calculate_map_at_k(recommended_items, ground_truth_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculates Mean Average Precision at K (MAP@K).\n",
    "    recommended_items: List of recommended item IDs (ordered by relevance).\n",
    "    ground_truth_items: Set of relevant item IDs.\n",
    "    \"\"\"\n",
    "    if not ground_truth_items:\n",
    "        return 0.0\n",
    "\n",
    "    relevant_count = 0\n",
    "    precision_sum = 0.0\n",
    "\n",
    "    for i, item_id in enumerate(recommended_items[:k]):\n",
    "        if item_id in ground_truth_items:\n",
    "            relevant_count += 1\n",
    "            precision_sum += relevant_count / (i + 1)\n",
    "    \n",
    "    return precision_sum / min(len(ground_truth_items), k) if relevant_count > 0 else 0.0\n",
    "\n",
    "\n",
    "def calculate_ndcg_at_k(recommended_items, ground_truth_items, k=10):\n",
    "    \"\"\"\n",
    "    Calculates Normalized Discounted Cumulative Gain at K (NDCG@K).\n",
    "    recommended_items: List of recommended item IDs (ordered by relevance).\n",
    "    ground_truth_items: Set of relevant item IDs.\n",
    "    \"\"\"\n",
    "    if not ground_truth_items:\n",
    "        return 0.0\n",
    "\n",
    "    # Create a relevance score list for NDCG calculation\n",
    "    # 1 if item is relevant, 0 otherwise\n",
    "    relevance = [1 if item_id in ground_truth_items else 0 for item_id in recommended_items[:k]]\n",
    "\n",
    "    # For NDCG, we need a list of scores for actual and ideal ordering.\n",
    "    # The `ndcg_score` function from sklearn expects a 2D array for y_true (relevance)\n",
    "    # and y_score (predicted scores/rankings).\n",
    "    # Since our recommendations are already ranked, we can use a simple array.\n",
    "    # The ideal_dcg assumes all ground_truth_items are ranked perfectly at the top.\n",
    "    \n",
    "    # y_true should represent the relevance of each item in the *recommended list*.\n",
    "    # y_score can be a list of dummy scores, as long as it preserves the ranking.\n",
    "    # We'll use the relevance list itself for y_true and a descending range for y_score\n",
    "    # to indicate the ranking.\n",
    "    \n",
    "    # Ensure y_true and y_score have the same length (k)\n",
    "    y_true = np.asarray([relevance])\n",
    "    # A simple descending score for the recommended items\n",
    "    y_score = np.asarray([np.arange(k, 0, -1)])\n",
    "    \n",
    "    # If the length of relevance is less than k, pad with zeros\n",
    "    if len(relevance) < k:\n",
    "        relevance.extend([0] * (k - len(relevance)))\n",
    "    \n",
    "    try:\n",
    "        # Use relevance scores directly for y_true for `ndcg_score`\n",
    "        # and a proxy for the predicted scores (e.g., inverse of rank)\n",
    "        return ndcg_score([relevance], [list(range(k, 0, -1))])\n",
    "    except ValueError as e:\n",
    "        # This error can occur if all y_true values are zero (no relevant items)\n",
    "        # or if the dimensions don't match.\n",
    "        # If no relevant items are found in recommendations, NDCG is 0.\n",
    "        print(f\"NDCG calculation error: {e}. Returning 0.0.\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "print(\"\\nStarting evaluation for MAP@10 and NDCG@10...\")\n",
    "user_ids_to_evaluate = test_rating['user_id'].unique()\n",
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "\n",
    "# Filter users who have ratings in the training set\n",
    "users_with_train_data = train_rating['user_id'].unique()\n",
    "user_ids_for_evaluation = [uid for uid in user_ids_to_evaluate if uid in users_with_train_data]\n",
    "\n",
    "if not user_ids_for_evaluation:\n",
    "    print(\"No users with sufficient data in both train and test sets for evaluation. Please check your data split.\")\n",
    "else:\n",
    "    for user_id in tqdm(user_ids_for_evaluation, desc=\"Evaluating users\"):\n",
    "        # Get ground truth from the test set\n",
    "        ground_truth_anime_ids = set(test_rating[\n",
    "            (test_rating['user_id'] == user_id) & (test_rating['rating'] >= 7) # Consider ratings >= 7 as \"relevant\"\n",
    "        ]['anime_id'].tolist())\n",
    "\n",
    "        if not ground_truth_anime_ids:\n",
    "            continue # Skip users with no relevant items in test set\n",
    "\n",
    "        # Generate recommendations based on the training data\n",
    "        # Ensure 'rating_clean' is passed correctly, or 'train_rating' for generating recommendations\n",
    "        recommendations = recommend_for_user(user_id, train_rating, anime_similarity_matrix, top_k=10)\n",
    "        recommended_anime_ids = [rec['anime_id'] for rec in recommendations]\n",
    "\n",
    "        # Calculate MAP@10\n",
    "        map_scores.append(calculate_map_at_k(recommended_anime_ids, ground_truth_anime_ids, k=10))\n",
    "\n",
    "        # Calculate NDCG@10\n",
    "        ndcg_scores.append(calculate_ndcg_at_k(recommended_anime_ids, ground_truth_anime_ids, k=10))\n",
    "\n",
    "    avg_map_at_10 = np.mean(map_scores) if map_scores else 0\n",
    "    avg_ndcg_at_10 = np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "\n",
    "    print(f\"\\n Evaluation Results\")\n",
    "    print(f\"Average MAP@10: {avg_map_at_10:.4f}\")\n",
    "    print(f\"Average NDCG@10: {avg_ndcg_at_10:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 571,
     "sourceId": 1094,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7742884,
     "sourceId": 12285968,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
